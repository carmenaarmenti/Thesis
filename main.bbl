\begin{thebibliography}{10}

\bibitem{allamanis2017learning}
M.~Allamanis, M.~Brockschmidt, and M.~Khademi.
\newblock Learning to represent programs with graphs.
\newblock {\em arXiv preprint arXiv:1711.00740}, 2017.

\bibitem{allamanis2021self}
M.~Allamanis, H.~Jackson-Flux, and M.~Brockschmidt.
\newblock Self-supervised bug detection and repair.
\newblock {\em Advances in Neural Information Processing Systems},
  34:27865--27876, 2021.

\bibitem{alon2018code2seq}
U.~Alon, S.~Brody, O.~Levy, and E.~Yahav.
\newblock code2seq: Generating sequences from structured representations of
  code.
\newblock {\em arXiv preprint arXiv:1808.01400}, 2018.

\bibitem{alon2019code2vec}
U.~Alon, M.~Zilberstein, O.~Levy, and E.~Yahav.
\newblock code2vec: Learning distributed representations of code.
\newblock {\em Proceedings of the ACM on Programming Languages}, 3(POPL):1--29,
  2019.

\bibitem{barchi2022deep}
F.~Barchi, E.~Parisi, A.~Bartolini, and A.~Acquaviva.
\newblock Deep learning approaches to source code analysis for optimization of
  heterogeneous systems: Recent results, challenges and opportunities.
\newblock {\em Journal of Low Power Electronics and Applications}, 12(3):37,
  2022.

\bibitem{bengio2009curriculum}
Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston.
\newblock Curriculum learning.
\newblock In {\em Proceedings of the 26th annual international conference on
  machine learning}, pages 41--48, 2009.

\bibitem{bhatia2016automated}
S.~Bhatia and R.~Singh.
\newblock Automated correction for syntax errors in programming assignments
  using recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1603.06129}, 2016.

\bibitem{brauckmann2020compiler}
A.~Brauckmann, A.~Goens, S.~Ertel, and J.~Castrillon.
\newblock Compiler-based graph representations for deep learning models of
  code.
\newblock In {\em Proceedings of the 29th International Conference on Compiler
  Construction}, pages 201--211, 2020.

\bibitem{bui2018cross}
N.~D. Bui, L.~Jiang, and Y.~Yu.
\newblock Cross-language learning for program classification using bilateral
  tree-based convolutional neural networks.
\newblock In {\em Workshops at the Thirty-Second AAAI Conference on Artificial
  Intelligence}, 2018.

\bibitem{chen2015webly}
X.~Chen and A.~Gupta.
\newblock Webly supervised learning of convolutional networks.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 1431--1439, 2015.

\bibitem{cirik2016visualizing}
V.~Cirik, E.~Hovy, and L.-P. Morency.
\newblock Visualizing and understanding curriculum learning for long short-term
  memory networks.
\newblock {\em arXiv preprint arXiv:1611.06204}, 2016.

\bibitem{Cirik2016VisualizingAU}
V.~Cirik, E.~H. Hovy, and L.-P. Morency.
\newblock Visualizing and understanding curriculum learning for long short-term
  memory networks.
\newblock {\em ArXiv}, abs/1611.06204, 2016.

\bibitem{el2020student}
R.~El-Bouri, D.~Eyre, P.~Watkinson, T.~Zhu, and D.~Clifton.
\newblock Student-teacher curriculum learning via reinforcement learning:
  predicting hospital inpatient admission location.
\newblock In {\em International Conference on Machine Learning}, pages
  2848--2857. PMLR, 2020.

\bibitem{ELMAN199371}
J.~L. Elman.
\newblock Learning and development in neural networks: the importance of
  starting small.
\newblock {\em Cognition}, 48(1):71--99, 1993.

\bibitem{fan2018learning}
Y.~Fan, F.~Tian, T.~Qin, X.-Y. Li, and T.-Y. Liu.
\newblock Learning to teach.
\newblock {\em arXiv preprint arXiv:1805.03643}, 2018.

\bibitem{florensa2017reverse}
C.~Florensa, D.~Held, M.~Wulfmeier, M.~Zhang, and P.~Abbeel.
\newblock Reverse curriculum generation for reinforcement learning.
\newblock In {\em Conference on robot learning}, pages 482--495. PMLR, 2017.

\bibitem{gong2019multi}
C.~Gong, J.~Yang, and D.~Tao.
\newblock Multi-modal curriculum learning over graphs.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  10(4):1--25, 2019.

\bibitem{graves2017automated}
A.~Graves, M.~G. Bellemare, J.~Menick, R.~Munos, and K.~Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock In {\em international conference on machine learning}, pages
  1311--1320. PMLR, 2017.

\bibitem{grigorik2012github}
I.~Grigorik.
\newblock The github archive.
\newblock {\em URL: https://githubarchive. org}, 2012.

\bibitem{guo2018curriculumnet}
S.~Guo, W.~Huang, H.~Zhang, C.~Zhuang, D.~Dong, M.~R. Scott, and D.~Huang.
\newblock Curriculumnet: Weakly supervised learning from large-scale web
  images.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 135--150, 2018.

\bibitem{hacohen2019power}
G.~Hacohen and D.~Weinshall.
\newblock On the power of curriculum learning in training deep networks.
\newblock In {\em International Conference on Machine Learning}, pages
  2535--2544. PMLR, 2019.

\bibitem{haj2020neurovectorizer}
A.~Haj-Ali, N.~K. Ahmed, T.~Willke, Y.~S. Shao, K.~Asanovic, and I.~Stoica.
\newblock Neurovectorizer: End-to-end vectorization with deep reinforcement
  learning.
\newblock In {\em Proceedings of the 18th ACM/IEEE International Symposium on
  Code Generation and Optimization}, pages 242--255, 2020.

\bibitem{hindle2016naturalness}
A.~Hindle, E.~T. Barr, M.~Gabel, Z.~Su, and P.~Devanbu.
\newblock On the naturalness of software.
\newblock {\em Communications of the ACM}, 59(5):122--131, 2016.

\bibitem{iyer2016summarizing}
S.~Iyer, I.~Konstas, A.~Cheung, and L.~Zettlemoyer.
\newblock Summarizing source code using a neural attention model.
\newblock In {\em Proceedings of the 54th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 2073--2083, 2016.

\bibitem{jiang2014easy}
L.~Jiang, D.~Meng, T.~Mitamura, and A.~G. Hauptmann.
\newblock Easy samples first: Self-paced reranking for zero-example multimedia
  search.
\newblock In {\em Proceedings of the 22nd ACM international conference on
  Multimedia}, pages 547--556, 2014.

\bibitem{kocmi2017curriculum}
T.~Kocmi and O.~Bojar.
\newblock Curriculum learning and minibatch bucketing in neural machine
  translation.
\newblock {\em arXiv preprint arXiv:1707.09533}, 2017.

\bibitem{krueger2009}
K.~A. Krueger and P.~Dayan.
\newblock Flexible shaping: How learning in small steps helps.
\newblock {\em Cognition}, 110(3):380--394, 2009.

\bibitem{kumar2010self}
M.~Kumar, B.~Packer, and D.~Koller.
\newblock Self-paced learning for latent variable models.
\newblock {\em Advances in neural information processing systems}, 23, 2010.

\bibitem{le2016history}
X.~B.~D. Le, D.~Lo, and C.~Le~Goues.
\newblock History driven program repair.
\newblock In {\em 2016 IEEE 23rd international conference on software analysis,
  evolution, and reengineering (SANER)}, volume~1, pages 213--224. IEEE, 2016.

\bibitem{Leclair2020}
A.~LeClair, S.~Haque, L.~Wu, and C.~McMillan.
\newblock Improved code summarization via a graph neural network.
\newblock {\em CoRR}, abs/2004.02843, 2020.

\bibitem{Levenshtein_SPD66}
V.~I. Levenshtein.
\newblock Binary codes capable of correcting deletions, insertions and
  reversals.
\newblock {\em Soviet Physics Doklady}, 10(8):707--710, feb 1966.
\newblock Doklady Akademii Nauk SSSR, V163 No4 845-848 1965.

\bibitem{Mastropaolo2022}
A.~Mastropaolo, L.~Pascarella, and G.~Bavota.
\newblock Using deep learning to generate complete log statements.
\newblock {\em CoRR}, abs/2201.04837, 2022.

\bibitem{matiisen2019teacher}
T.~Matiisen, A.~Oliver, T.~Cohen, and J.~Schulman.
\newblock Teacher--student curriculum learning.
\newblock {\em IEEE transactions on neural networks and learning systems},
  31(9):3732--3740, 2019.

\bibitem{mendis2019ithemal}
C.~Mendis, A.~Renda, S.~Amarasinghe, and M.~Carbin.
\newblock Ithemal: Accurate, portable and fast basic block throughput
  estimation using deep neural networks.
\newblock In {\em International Conference on machine learning}, pages
  4505--4515. PMLR, 2019.

\bibitem{mou2016convolutional}
L.~Mou, G.~Li, L.~Zhang, T.~Wang, and Z.~Jin.
\newblock Convolutional neural networks over tree structures for programming
  language processing.
\newblock In {\em Thirtieth AAAI conference on artificial intelligence}, 2016.

\bibitem{narvekar2017autonomous}
S.~Narvekar, J.~Sinapov, and P.~Stone.
\newblock Autonomous task sequencing for customized curriculum design in
  reinforcement learning.
\newblock In {\em IJCAI}, pages 2536--2542, 2017.

\bibitem{platanios2019competence}
E.~A. Platanios, O.~Stretcu, G.~Neubig, B.~Poczos, and T.~M. Mitchell.
\newblock Competence-based curriculum learning for neural machine translation.
\newblock {\em arXiv preprint arXiv:1903.09848}, 2019.

\bibitem{pradel2020typewriter}
M.~Pradel, G.~Gousios, J.~Liu, and S.~Chandra.
\newblock Typewriter: Neural type prediction with search-based validation.
\newblock In {\em Proceedings of the 28th ACM Joint Meeting on European
  Software Engineering Conference and Symposium on the Foundations of Software
  Engineering}, pages 209--220, 2020.

\bibitem{qu2018curriculum}
M.~Qu, J.~Tang, and J.~Han.
\newblock Curriculum learning for heterogeneous star network embedding via deep
  reinforcement learning.
\newblock In {\em Proceedings of the Eleventh ACM International Conference on
  Web Search and Data Mining}, pages 468--476, 2018.

\bibitem{raychev2014code}
V.~Raychev, M.~Vechev, and E.~Yahav.
\newblock Code completion with statistical language models.
\newblock In {\em Proceedings of the 35th ACM SIGPLAN Conference on Programming
  Language Design and Implementation}, pages 419--428, 2014.

\bibitem{ren2018self}
Z.~Ren, D.~Dong, H.~Li, and C.~Chen.
\newblock Self-paced prioritized curriculum learning with coverage penalty in
  deep reinforcement learning.
\newblock {\em IEEE transactions on neural networks and learning systems},
  29(6):2216--2226, 2018.

\bibitem{santos2018syntax}
E.~A. Santos, J.~C. Campbell, D.~Patel, A.~Hindle, and J.~N. Amaral.
\newblock Syntax and sensibility: Using language models to detect and correct
  syntax errors.
\newblock In {\em 2018 IEEE 25th International Conference on Software Analysis,
  Evolution and Reengineering (SANER)}, pages 311--322. IEEE, 2018.

\bibitem{scarselli2008graph}
F.~Scarselli, M.~Gori, A.~C. Tsoi, M.~Hagenbuchner, and G.~Monfardini.
\newblock The graph neural network model.
\newblock {\em IEEE transactions on neural networks}, 20(1):61--80, 2008.

\bibitem{tay2019simple}
Y.~Tay, S.~Wang, L.~A. Tuan, J.~Fu, M.~C. Phan, X.~Yuan, J.~Rao, S.~C. Hui, and
  A.~Zhang.
\newblock Simple and effective curriculum pointer-generator networks for
  reading comprehension over long narratives.
\newblock {\em arXiv preprint arXiv:1905.10847}, 2019.

\bibitem{Tufano2019}
M.~Tufano, C.~Watson, G.~Bavota, M.~D. Penta, M.~White, and D.~Poshyvanyk.
\newblock An empirical study on learning bug-fixing patches in the wild via
  neural machine translation.
\newblock {\em ACM Trans. Softw. Eng. Methodol.}, 28(4), sep 2019.

\bibitem{Wang2020}
X.~Wang, Y.~Chen, and W.~Zhu.
\newblock A comprehensive survey on curriculum learning.
\newblock {\em CoRR}, abs/2010.13166, 2020.

\bibitem{wang2021survey}
X.~Wang, Y.~Chen, and W.~Zhu.
\newblock A survey on curriculum learning.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2021.

\bibitem{weinshall2018curriculum}
D.~Weinshall, G.~Cohen, and D.~Amir.
\newblock Curriculum learning by transfer learning: Theory and experiments with
  deep networks.
\newblock In {\em International Conference on Machine Learning}, pages
  5238--5246. PMLR, 2018.

\bibitem{xu2020curriculum}
B.~Xu, L.~Zhang, Z.~Mao, Q.~Wang, H.~Xie, and Y.~Zhang.
\newblock Curriculum learning for natural language understanding.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 6095--6104, 2020.

\bibitem{lizard}
T.~Yin.
\newblock \href{https://github.com/terryyin/lizard}{Lizard}.

\bibitem{zaremba2014learning}
W.~Zaremba and I.~Sutskever.
\newblock Learning to execute.
\newblock {\em arXiv preprint arXiv:1410.4615}, 2014.

\end{thebibliography}
