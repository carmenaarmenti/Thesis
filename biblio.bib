@article{Tufano2019, 
author = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys}, 
title = {An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation}, 
year = {2019}, 
issue_date = {October 2019}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
volume = {28}, 
number = {4}, 
issn = {1049-331X}, 
url = {https://doi.org/10.1145/3340544}, 
doi = {10.1145/3340544}, 
abstract = {Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.}, 
journal = {ACM Trans. Softw. Eng. Methodol.}, 
month = {sep}, 
articleno = {19}, 
numpages = {29}, 
keywords = {Neural machine translation, bug-fixes}} 

@article{Levenshtein_SPD66,
  abstract = {Seems to be the first person to define what became  known as the (simple) edit-distance and show it to be a  metric. Paper mostly about constructing optimal codes  to transmit such corrections.},
  added-at = {2009-09-11T19:06:23.000+0200},
  author = {Levenshtein, Vladimir Iosifovich},
  biburl = {https://www.bibsonomy.org/bibtex/220546d80ce76f58c6ef6ece9dd5f5056/jimregan},
  interhash = {55f7ad93fcb9ae3ed999afaa6e24937d},
  intrahash = {20546d80ce76f58c6ef6ece9dd5f5056},
  journal = {Soviet Physics Doklady},
  keywords = {edit-distance},
  month = {feb},
  note = {Doklady Akademii Nauk SSSR, V163 No4 845-848 1965},
  number = {8},
  pages = {707--710},
  timestamp = {2009-09-11T19:06:23.000+0200},
  title = {Binary codes capable of correcting deletions, insertions and reversals.},
  volume = {10},
  year = {1966}}

@article{Leclair2020,
  author    = {Alexander LeClair and
               Sakib Haque and
               Lingfei Wu and
               Collin McMillan},
  title     = {Improved Code Summarization via a Graph Neural Network},
  journal   = {CoRR},
  volume    = {abs/2004.02843},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.02843},
  eprinttype = {arXiv},
  eprint    = {2004.02843},
  timestamp = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-02843.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@article{Mastropaolo2022,
  author    = {Antonio Mastropaolo and
               Luca Pascarella and
               Gabriele Bavota},
  title     = {Using Deep Learning to Generate Complete Log Statements},
  journal   = {CoRR},
  volume    = {abs/2201.04837},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.04837},
  eprinttype = {arXiv},
  eprint    = {2201.04837},
  timestamp = {Thu, 20 Jan 2022 14:21:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-04837.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@ONLINE {lizard,
  title= {\href{https://github.com/terryyin/lizard}{Lizard}},
  url= {https://github.com/terryyin/lizard},
  urldate = {2022-09-21},
  author = {Terry Yin}}

@article{Wang2020,
  author    = {Xin Wang and
               Yudong Chen and
               Wenwu Zhu},
  title     = {A Comprehensive Survey on Curriculum Learning},
  journal   = {CoRR},
  volume    = {abs/2010.13166},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.13166},
  eprinttype = {arXiv},
  eprint    = {2010.13166},
  timestamp = {Wed, 17 Feb 2021 08:14:46 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-13166.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@article{ELMAN199371,
	abstract = {It is a striking fact that in humans the greatest learning occurs precisely at that point in time - childhood - when the most dramatic maturational changes also occur. This report describes possible synergistic interactions between maturational change and the ability to learn a complex domain (language), as investigated in connectionist networks. The networks are trained to process complex sentences involving relative clauses, number agreement, and several types of verb argument structure. Training fails in the case of networks which are fully formed and `adultlike' in their capacity. Training succeeds only when networks begin with limited working memory and gradually `mature' to the adult state. This result suggests that rather than being a limitation, developmental restrictions on resources may constitute a necessary prerequisite for mastering certain complex domains. Specifically, successful learning may depend on starting small.},
	author = {Jeffrey L. Elman},
	doi = {https://doi.org/10.1016/0010-0277(93)90058-4},
	issn = {0010-0277},
	journal = {Cognition},
	number = {1},
	pages = {71-99},
	title = {Learning and development in neural networks: the importance of starting small},
	url = {https://www.sciencedirect.com/science/article/pii/0010027793900584},
	volume = {48},
	year = {1993},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/0010027793900584},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(93)90058-4}}

@article{Cirik2016VisualizingAU,
  title={Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks},
  author={Volkan Cirik and Eduard H. Hovy and Louis-Philippe Morency},
  journal={ArXiv},
  year={2016},
  volume={abs/1611.06204}}

@article{krueger2009,
  title={Flexible shaping: How learning in small steps helps},
  author={Krueger, Kai A and Dayan, Peter},
  journal={Cognition},
  volume={110},
  number={3},
  pages={380--394},
  year={2009},
  publisher={Elsevier}}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M and Packer, Benjamin and Koller, Daphne},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}}

@article{fan2018learning,
  title={Learning to teach},
  author={Fan, Yang and Tian, Fei and Qin, Tao and Li, Xiang-Yang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1805.03643},
  year={2018}}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}}

  @inproceedings{hacohen2019power,
  title={On the power of curriculum learning in training deep networks},
  author={Hacohen, Guy and Weinshall, Daphna},
  booktitle={International Conference on Machine Learning},
  pages={2535--2544},
  year={2019},
  organization={PMLR}}

  @article{platanios2019competence,
  title={Competence-based curriculum learning for neural machine translation},
  author={Platanios, Emmanouil Antonios and Stretcu, Otilia and Neubig, Graham and Poczos, Barnabas and Mitchell, Tom M},
  journal={arXiv preprint arXiv:1903.09848},
  year={2019}}

  @inproceedings{soviany2020image,
  title={Image difficulty curriculum for generative adversarial networks (CuGAN)},
  author={Soviany, Petru and Ardei, Claudiu and Ionescu, Radu Tudor and Leordeanu, Marius},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={3463--3472},
  year={2020}}

  @inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}}

  @article{hindle2016naturalness,
  title={On the naturalness of software},
  author={Hindle, Abram and Barr, Earl T and Gabel, Mark and Su, Zhendong and Devanbu, Premkumar},
  journal={Communications of the ACM},
  volume={59},
  number={5},
  pages={122--131},
  year={2016},
  publisher={ACM New York, NY, USA}}

  @article{allamanis2018survey,
  title={A survey of machine learning for big code and naturalness},
  author={Allamanis, Miltiadis and Barr, Earl T and Devanbu, Premkumar and Sutton, Charles},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={4},
  pages={1--37},
  year={2018},
  publisher={ACM New York, NY, USA}}

  @inproceedings{raychev2014code,
  title={Code completion with statistical language models},
  author={Raychev, Veselin and Vechev, Martin and Yahav, Eran},
  booktitle={Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={419--428},
  year={2014}}