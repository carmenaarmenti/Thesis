@article{Tufano2019, 
author = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys}, 
title = {An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation}, 
year = {2019}, 
issue_date = {October 2019}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
volume = {28}, 
number = {4}, 
issn = {1049-331X}, 
url = {https://doi.org/10.1145/3340544}, 
doi = {10.1145/3340544}, 
abstract = {Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.}, 
journal = {ACM Trans. Softw. Eng. Methodol.}, 
month = {sep}, 
articleno = {19}, 
numpages = {29}, 
keywords = {Neural machine translation, bug-fixes}} 

@article{Levenshtein_SPD66,
  abstract = {Seems to be the first person to define what became  known as the (simple) edit-distance and show it to be a  metric. Paper mostly about constructing optimal codes  to transmit such corrections.},
  added-at = {2009-09-11T19:06:23.000+0200},
  author = {Levenshtein, Vladimir Iosifovich},
  biburl = {https://www.bibsonomy.org/bibtex/220546d80ce76f58c6ef6ece9dd5f5056/jimregan},
  interhash = {55f7ad93fcb9ae3ed999afaa6e24937d},
  intrahash = {20546d80ce76f58c6ef6ece9dd5f5056},
  journal = {Soviet Physics Doklady},
  keywords = {edit-distance},
  month = {feb},
  note = {Doklady Akademii Nauk SSSR, V163 No4 845-848 1965},
  number = {8},
  pages = {707--710},
  timestamp = {2009-09-11T19:06:23.000+0200},
  title = {Binary codes capable of correcting deletions, insertions and reversals.},
  volume = {10},
  year = {1966}}

@article{Leclair2020,
  author    = {Alexander LeClair and
               Sakib Haque and
               Lingfei Wu and
               Collin McMillan},
  title     = {Improved Code Summarization via a Graph Neural Network},
  journal   = {CoRR},
  volume    = {abs/2004.02843},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.02843},
  eprinttype = {arXiv},
  eprint    = {2004.02843},
  timestamp = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-02843.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@article{Mastropaolo2022,
  author    = {Antonio Mastropaolo and
               Luca Pascarella and
               Gabriele Bavota},
  title     = {Using Deep Learning to Generate Complete Log Statements},
  journal   = {CoRR},
  volume    = {abs/2201.04837},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.04837},
  eprinttype = {arXiv},
  eprint    = {2201.04837},
  timestamp = {Thu, 20 Jan 2022 14:21:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-04837.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@ONLINE {lizard,
  title= {\href{https://github.com/terryyin/lizard}{Lizard}},
  url= {https://github.com/terryyin/lizard},
  urldate = {2022-09-21},
  author = {Terry Yin}}

@article{Wang2020,
  author    = {Xin Wang and
               Yudong Chen and
               Wenwu Zhu},
  title     = {A Comprehensive Survey on Curriculum Learning},
  journal   = {CoRR},
  volume    = {abs/2010.13166},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.13166},
  eprinttype = {arXiv},
  eprint    = {2010.13166},
  timestamp = {Wed, 17 Feb 2021 08:14:46 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-13166.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@article{ELMAN199371,
	abstract = {It is a striking fact that in humans the greatest learning occurs precisely at that point in time - childhood - when the most dramatic maturational changes also occur. This report describes possible synergistic interactions between maturational change and the ability to learn a complex domain (language), as investigated in connectionist networks. The networks are trained to process complex sentences involving relative clauses, number agreement, and several types of verb argument structure. Training fails in the case of networks which are fully formed and `adultlike' in their capacity. Training succeeds only when networks begin with limited working memory and gradually `mature' to the adult state. This result suggests that rather than being a limitation, developmental restrictions on resources may constitute a necessary prerequisite for mastering certain complex domains. Specifically, successful learning may depend on starting small.},
	author = {Jeffrey L. Elman},
	doi = {https://doi.org/10.1016/0010-0277(93)90058-4},
	issn = {0010-0277},
	journal = {Cognition},
	number = {1},
	pages = {71-99},
	title = {Learning and development in neural networks: the importance of starting small},
	url = {https://www.sciencedirect.com/science/article/pii/0010027793900584},
	volume = {48},
	year = {1993},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/0010027793900584},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(93)90058-4}}

@article{Cirik2016VisualizingAU,
  title={Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks},
  author={Volkan Cirik and Eduard H. Hovy and Louis-Philippe Morency},
  journal={ArXiv},
  year={2016},
  volume={abs/1611.06204}}

@article{Elman1,
author = {Elman, Jeffrey},
year = {1993},
month = {08},
pages = {71-99},
title = {Learning and Development in Neural Networks: the Importance of Starting Small},
volume = {48},
journal = {Cognition},
doi = {10.1016/0010-0277(93)90058-4}}

@article{krueger2009,
  title={Flexible shaping: How learning in small steps helps},
  author={Krueger, Kai A and Dayan, Peter},
  journal={Cognition},
  volume={110},
  number={3},
  pages={380--394},
  year={2009},
  publisher={Elsevier}}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}}